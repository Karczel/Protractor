\chapter*{Abstract}
\label{chap:abstract}
\addcontentsline{toc}{chapter}{\nameref{chap:abstract}}

Currently, Generative AI has significantly advanced in producing high-quality video content, but it also introduces risks such as deepfake misuse, copyright infringement, and malicious manipulation. The Protractor project presents an AI-driven video poisoning processor designed to counteract the threats posed by Generative AI video models. By adding imperceptible perturbations to videos, Protractor ensures that while the video remains unchanged to the human eye, AI models misinterpret and degrade their outputs when trained on poisoned data.

The system leverages Breaking Temporal Consistency (BTC-UAP) and Spatially Transformed Adversarial Attacks (stAdv) to disrupt both frame-by-frame spatial details and motion-based temporal consistency, preventing AI from accurately learning patterns from poisoned videos. Additionally, the project implements adversarial noise embedding, perceptual similarity loss, and automated AI pipeline optimizations to maintain high fidelity for human viewers while corrupting AI training datasets.

The Protractor system is built for content creators, artists, and copyright holders who wish to protect their work from unauthorized AI training. Experimental results show that video poisoning significantly disrupts AI-generated outputs, making it a practical defense against AI exploitation and data misuse.

Keywords: Video Poisoning, Generative AI, Adversarial Attack, Deepfake Protection, AI Security