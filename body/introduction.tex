\chapter{Introduction}
\label{chap:introduction}

\section{Background}
\label{section:background}

Video Generative AI[0] refers to artificial intelligence models that create videos based on textual descriptions, images, or existing video inputs. 

The widespread use of this AI has led to concerns about copyright infringement[1], as AI models[2] often rely on vast datasets[3] scraped from the internet[4], including copyrighted content[5], without explicit permission from original creators[6]. Many artists and content creators advocate for stricter regulations to protect their works from being used without consent.

One of the most alarming consequences of AI-generated video technology is impersonation[7], often referred to as "deepfakes[8]." AI can create realistic videos of individuals, making them appear to say or do things they never did. This poses risks in identity theft[9], misinformation[10], fraud[11], and political manipulation[12]. The ability to create hyper-realistic fake videos raises concerns about trust in digital content and calls for advanced detection methods to counteract malicious use.

Data poisoning is a method of corrupting AI models by injecting misleading or harmful data into their training sets[13], ensuring that generative models[14] cannot easily exploit original artistic content. However, it would be considered an aspect of data security[15], and restrict malicious actors from exploiting your data against your interests.

\section{Problem Statement}
\label{section:problem-statement}

Problems from the invention of Video-output Generative AI

1. Deepfake[8]
    1.1. Identity theft[9]
    1.2. Forgery of False Evidence of crimes
    1.3. Defamation from non-consensual explicit generated video
2. Grifters
    2.1. Copyright Infringement
    2.2. Dead internet theory 

Technical Problems

1. There is currently no existing video poisoning processor, but there is research on video poisoning tactics.
2. Frame-by-Frame poisoning with static Image poisoning processor as an alternative.
    2.1. Manually poisoning frame by frame is inconvenient for production use.
    2.2. Processing time scales horribly with video duration and fps.
    2.3. Static Image poisoning tactics is less effective against Video generative AI.

\section{Solution Overview}
\label{section:solution-overview}

This software seeks to simplify the process of video poisoning to be as easy as a few clicks.
We'd only need the user to inputing their video, set some preferences, start the process and wait for the poisoned video output in their designated folder.
While being effective against generative ai and efficiently optimize hardware resources to process larger video; ranging from 5 minutes to 2 hours, to be processed fast and reliable enough for our target users such as filmmakers, content creators, and studios to incorporate this in their workflow. 

\subsection{Features}
\label{subsection:features}

\begin{enumerate}[leftmargin=80pt]
    \item Video Input: Input your video to poison
    \item Perturbation Settings: Set predefined Parameters such as perturbation weights or quality to set the perturbation strength and output quality. More parameters may be added depending on the available parameters of the system's poisoning methods.
    \item Output folder: User can select where the output will be stored when the video poisoning process has finished.
    \item Start Poisoning: Click to start the poisoning process. The process cannot be stopped while it is running until the process finishes.
    \item Hardware optimization: Optimize the available hardware to minimize processing time duration. This would be done automatically but may allow users to set hardware themselves if deemed appropriate.
\end{enumerate}

\section{Target User}
\label{section:target-user}

\begin{itemize}
    \item \textbf{Digital Content Creators \& Video Artists:} Professionals and amateurs (e.g., filmmakers, digital artists) concerned about AI scraping their work. Protractor ensures AI cannot accurately process their videos, preventing misuse.
    
    \item \textbf{Researchers in AI Security \& Adversarial Machine Learning:} AI ethics researchers and security analysts studying adversarial robustness. Since current AI poisoning methods mainly target images, Protractor provides a tool for testing adversarial perturbations in videos.
    
    \item \textbf{Legal and Copyright Protection Experts:} Media attorneys and digital rights organizations dealing with AI-generated deepfakes and content misuse. Protractor helps protect intellectual property from unauthorized AI training.
    
    \item \textbf{Industry Professionals in Media \& Entertainment:} Streaming platforms, game developers, and animation studios facing AI replication of artistic styles. Protractor’s poisoning techniques prevent AI from learning and mimicking their creative work.
\end{itemize}

\section{Benefit}
\label{section:benefit}

The Protractor system protects video content from unauthorized AI training by applying adversarial 
techniques that disrupt AI perception while remaining imperceptible to humans. It prevents AI from
 accurately processing videos, reducing the risk of deepfake generation and unauthorized replication. 
 This enhances intellectual property protection for creators and safeguards the creative industry 
 from AI-driven content theft. Additionally, Protractor supports AI security research, helping 
 experts study AI vulnerabilities in video poisoning. Its easy-to-use implementation allows content 
 creators and researchers to apply AI poisoning without requiring advanced technical expertise.

\section{Terminology}
\label{section:terminology}

\subsection{Background}
\label{subsection:Background}
[0]AI : artificial intelligence
[1]copyright infringement : violating copyright law over a content
[2]AI models : AI programs consisting of complex mathematical and computational techniques to process vast amounts of data and extract meaningful insights.
[3]datasets : collections of data used to train AI models.
[4]scraped from the internet : automatically collecting data from online sources, often using web crawlers or scrapers.
[5]copyrighted content : Any creative work (e.g., videos, images, music) legally protected under copyright law, requiring permission for use.
[6]original creators : The individuals or entities who produce and hold the legal rights to creative content.
[7]Impersonation : The act of fraudulently imitating a person, often using AI-generated media, to deceive others.
[8]deepfakes : AI-generated videos that convincingly replace a person’s likeness or voice with another, often for deceptive purposes.
[9]identity theft : The unauthorized use of someone’s personal information to commit fraud or other crimes.
[10]misinformation : False or misleading information spread unintentionally or deliberately, often amplified by AI-generated content.
[11]fraud : Deceptive actions intended to achieve financial or personal gain, sometimes involving AI-generated media.
[12]political manipulation : The use of deceptive tactics, such as deepfakes or AI-generated propaganda, to influence public opinion or elections.

Deepfake

Grifters

Dead internet theory
    genuine human interaction is overtaken by AI slop

Data Poisoning
Data Security
datasets
scraped

Adversarial Attack: A method to manipulate AI models by adding small, unnoticeable changes that cause errors.

Breaking Temporal Consistency (BTC-UAP): A technique that disrupts AI’s ability to track motion across video frames.

Spatially Transformed Adversarial Attack (stAdv): Alters video structure to mislead AI while keeping it unchanged for humans.

Deepfake: AI-generated fake media that manipulates video content realistically.

AI Poisoning: Modifying data to mislead AI models and prevent accurate learning.

Perceptual Similarity Metrics (LPIPS \& SSIM): Measures that compare AI and human perception of video similarity.

Universal Adversarial Perturbation (UAP): Small changes in visuals that significantly affect AI recognition without altering human perception.
